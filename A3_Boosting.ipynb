{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Boosting\n",
    "\n",
    "Freek van Geffen | s2633256 <br>\n",
    "Justin Kraaijenbrink | s2577984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, explained_variance_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "housing = pd.read_csv(path + '/data/Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization function to obtain standardized regression coefficients \n",
    "# for the linear regression model\n",
    "def Standardize(model, X_train, y_train, index):\n",
    "    X_train = X_train.drop(columns = 'const')\n",
    "    index = index.drop('const')\n",
    "    \n",
    "    sdy = np.std(y_train)\n",
    "    sdx = np.std(X_train[index]).values\n",
    "    coefs = model.params.drop('const')\n",
    "    \n",
    "    std_coefs = coefs.values / (sdy / sdx)\n",
    "    \n",
    "    out = pd.DataFrame(std_coefs, index = coefs.index, columns = ['Std. Beta']).sort_values(by = 'Std. Beta', ascending = False)\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the performance of the models\n",
    "def CalculateRMSE(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = np.sum((y_pred - y_test)**2) / len(y_test)\n",
    "    \n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test set\n",
    "np.random.RandomState(248)\n",
    "y = housing['price']\n",
    "X = housing.iloc[:, 1:]\n",
    "X = pd.get_dummies(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTuningResults3D(grid, param_test, parameter1, parameter2):\n",
    "    m = len(param_test[parameter1])\n",
    "    n = len(param_test[parameter2])\n",
    "    \n",
    "    param_name1 = 'param_' + parameter1\n",
    "    param_name2 = 'param_' + parameter2\n",
    "    X = np.reshape(grid.cv_results_[param_name1].data,[n,m])\n",
    "    Y = np.reshape(grid.cv_results_[param_name2].data,[n,m])\n",
    "    Z = np.reshape(grid.cv_results_['mean_test_score'],[n,m])\n",
    "    \n",
    "    Y = np.array(Y, dtype = float)\n",
    "    X = np.array(X, dtype = float)\n",
    "    \n",
    "    fig = plt.figure(figsize = (12,8))\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "    \n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel(parameter1, size = 13)\n",
    "    ax.set_ylabel(parameter2, size = 13)\n",
    "    ax.set_zlabel('Test explained variance', size = 13)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label=list(y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = xgb.XGBRegressor(\n",
    "    n_estimators=10000,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    n_jobs = -1,\n",
    "    seed=248)\n",
    "\n",
    "cvresult = xgb.cv(xgb1.get_xgb_params(), dtrain, num_boost_round=xgb1.n_estimators, nfold=5,\n",
    "                      metrics='rmse', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for optimal max depth and child weight\n",
    "param_test1 = {\n",
    " 'max_depth':range(1,11,1),\n",
    " 'min_child_weight':range(0,11,1)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBRegressor(n_estimators=81, \n",
    "                                                     objective= 'reg:squarederror',\n",
    "                                                     tree_method = 'auto',\n",
    "                                                     seed=248), \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs = -1,\n",
    "                        cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch1, param_test1, 'max_depth', 'min_child_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = xgb.XGBRegressor(\n",
    "    n_estimators=10000,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    max_depth = 4,\n",
    "    min_child_weights = 3,\n",
    "    n_jobs = -1,\n",
    "    seed=248)\n",
    "\n",
    "cvresult = xgb.cv(xgb2.get_xgb_params(), dtrain, num_boost_round=xgb2.n_estimators, nfold=5,\n",
    "                      metrics='rmse', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {'min_split_loss':[i/100.0 for i in range(0,2, 1)]}\n",
    "gsearch2 = GridSearchCV(estimator = xgb.XGBRegressor(n_estimators=55, \n",
    "                                                     objective= 'reg:squarederror',\n",
    "                                                     tree_method = 'hist',\n",
    "                                                     seed=248,\n",
    "                                                    max_depth = 4,\n",
    "                                                    min_child_weights = 3), \n",
    "                        param_grid = param_test2, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs = -1,\n",
    "                        cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = xgb.XGBRegressor(\n",
    "    n_estimators=10000,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    max_depth = 4,\n",
    "    min_child_weights = 3,\n",
    "    min_split_loss = 0,\n",
    "    n_jobs = -1,\n",
    "    seed=248)\n",
    "\n",
    "cvresult = xgb.cv(xgb3.get_xgb_params(), dtrain, num_boost_round=xgb3.n_estimators, nfold=5,\n",
    "                      metrics='rmse', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {'subsample':[i/100.0 for i in range(5,105, 5)],\n",
    "               'colsample_bytree':[i/100.0 for i in range(0,105, 5)]}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBRegressor( n_estimators=55, \n",
    "                                                  max_depth=4,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  min_split_loss = 0,\n",
    "                                                  objective = 'reg:squarederror',\n",
    "                                                  tree_method = 'auto',\n",
    "                                                  seed=248),\n",
    "                        param_grid = param_test3, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs=-1,\n",
    "                        cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch3, param_test3, 'subsample', 'colsample_bytree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = xgb.XGBRegressor(\n",
    "    n_estimators=10000,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    max_depth = 3,\n",
    "    min_child_weights = 0,\n",
    "    min_split_loss = 0,\n",
    "    colsample_bytree = 0.9,\n",
    "    subsample = 0.85,\n",
    "    n_jobs = -1,\n",
    "    seed=248)\n",
    "\n",
    "cvresult = xgb.cv(xgb4.get_xgb_params(), dtrain, num_boost_round=xgb4.n_estimators, nfold=5,\n",
    "                      metrics='rmse', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'reg_alpha':[0, 10**-5, 10**-4, 10**-3, 10**-2, 10**-2, 10**-1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = xgb.XGBRegressor( n_estimators=78, \n",
    "                                                  max_depth=4,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  min_split_loss = 0,\n",
    "                                                  colsample_bytree= 0.9,\n",
    "                                                  subsample = 0.85,\n",
    "                                                  objective = 'reg:squarederror',\n",
    "                                                  tree_method = 'auto',\n",
    "                                                  seed=248),\n",
    "                        param_grid = param_test4, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs=-1,\n",
    "                        cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calibrate number of boosting rounds\n",
    "xgb5 = xgb.XGBRegressor(\n",
    "    n_estimators=10000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3,\n",
    "    min_split_loss=0,\n",
    "    col_sample_bytree = 0.9,\n",
    "    subsample = 0.85,\n",
    "    req_alpha = 1000,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    seed=248,\n",
    "    n_jobs = -1)\n",
    "cvresult = xgb.cv(xgb5.get_xgb_params(), dtrain, num_boost_round=xgb5.n_estimators, nfold=5,\n",
    "                      metrics='rmse', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    "  'n_estimators' : range(50, 1000, 50),\n",
    " 'learning_rate' : [i/100.0 for i in range(1, 20, 1)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = xgb.XGBRegressor( \n",
    "                                                  max_depth=4,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  min_split_loss = 0,\n",
    "                                                  colsample_bytree= 0.9,\n",
    "                                                  subsample = 0.85,\n",
    "                                                  req_alpha = 1000,\n",
    "                                                  objective = 'reg:squarederror',\n",
    "                                                  tree_method = 'auto',\n",
    "                                                  seed=248),\n",
    "                        param_grid = param_test5, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs=-1,\n",
    "                        cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch5, param_test5, 'learning_rate', 'n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4a = {\n",
    "  'reg_alpha':[0, 10**-5, 10**-4, 10**-3, 10**-2, 10**-2, 10**-1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "gsearch4a = GridSearchCV(estimator = xgb.XGBRegressor( n_estimators=100, \n",
    "                                                      learning_rate = 0.1,\n",
    "                                                  max_depth=4,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  min_split_loss = 0,\n",
    "                                                  colsample_bytree= 0.9,\n",
    "                                                  subsample = 0.85,\n",
    "                                                  objective = 'reg:squarederror',\n",
    "                                                  tree_method = 'auto',\n",
    "                                                  seed=248),\n",
    "                        param_grid = param_test4a, \n",
    "                        scoring='explained_variance',\n",
    "                        n_jobs=-1,\n",
    "                        cv=5)\n",
    "gsearch4a.fit(X_train,y_train)\n",
    "gsearch4a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults(gsearch4, 'reg_alpha', 'L1 Regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final = xgb.XGBRegressor(\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3,\n",
    "    min_split_loss=0,\n",
    "    col_sample_bytree = 0.9,\n",
    "    subsample = .85,\n",
    "    req_alpha = 100,\n",
    "    objective= 'reg:squarederror',\n",
    "    tree_method = 'auto',\n",
    "    seed=248,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final.get_xgb_params()\n",
    "xgb_final.fit(X_train, y_train)\n",
    "y_pred = xgb_final.predict(X_test)\n",
    "\n",
    "print(CalculateRMSE(xgb_final, X_test, y_test))\n",
    "print(explained_variance_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(xgb_final.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and aggregate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_proteins = pd.read_csv(path+'/data/PAM50_proteins.csv')\n",
    "clinical = pd.read_csv(path+'/data/clinical_data_breast_cancer.csv')\n",
    "proteomes = pd.read_csv(path+'/data/77_cancer_proteomes_CPTAC_itraq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = proteomes.index.values\n",
    "proteomes_trans = proteomes.iloc[:,3:].T\n",
    "TCGA_ids = pd.DataFrame({\"Complete TCGA ID\":proteomes_trans.index.values})\n",
    "proteomes_trans.reset_index(inplace = True)\n",
    "proteomes_trans.columns.values[0] = 'Complete TCGA ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReformatID(ID):\n",
    "    \n",
    "    x = ID[3:7]\n",
    "    y = ID[0:2]\n",
    "    out = 'TCGA'+'-'+y+'-'+ x\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "proteomes_trans.iloc[:,0] = [ReformatID(element) for element in proteomes_trans.iloc[:,0]]\n",
    "proteomes_final = proteomes_trans.dropna(axis = 1)\n",
    "data = clinical.merge(proteomes_final, on = 'Complete TCGA ID')\n",
    "\n",
    "objects = data.dtypes[data.dtypes == object].index.values\n",
    "data_fact = data.copy(deep = True)\n",
    "\n",
    "for i in objects:\n",
    "    data_fact.loc[:, i] = pd.factorize(data_fact.loc[:, i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test set\n",
    "seed = np.random.RandomState(248)\n",
    "y = data_fact['PAM50 mRNA']\n",
    "X = data_fact.iloc[:, 30:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTuningResults3D(grid, param_test, parameter1, parameter2):\n",
    "    m = len(param_test[parameter1])\n",
    "    n = len(param_test[parameter2])\n",
    "    \n",
    "    param_name1 = 'param_' + parameter1\n",
    "    param_name2 = 'param_' + parameter2\n",
    "    X = np.reshape(grid.cv_results_[param_name1].data,[n,m])\n",
    "    Y = np.reshape(grid.cv_results_[param_name2].data,[n,m])\n",
    "    Z = np.reshape(grid.cv_results_['mean_test_score'],[n,m])\n",
    "    \n",
    "    Y = np.array(Y, dtype = float)\n",
    "    X = np.array(X, dtype = float)\n",
    "    \n",
    "    fig = plt.figure(figsize = (12,8))\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "    \n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel(parameter1, size = 14)\n",
    "    ax.set_ylabel(parameter2, size = 14)\n",
    "    ax.set_zlabel('Test accuracy', size = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label=list(y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = xgb.XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    num_class = 4,\n",
    "    objective= 'multi:softmax',\n",
    "    n_jobs = -1,\n",
    "    seed=248)\n",
    "\n",
    "cvresult = xgb.cv(xgb1.get_xgb_params(), dtrain, num_boost_round=xgb1.n_estimators, nfold=5,\n",
    "                      metrics='merror', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for optimal max depth and child weight\n",
    "param_test1 = {\n",
    " 'max_depth':range(1,11,1),\n",
    " 'min_child_weight':range(0,11,1)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(n_estimators=43, \n",
    "                                                     objective= 'multi:softmax',\n",
    "                                                     seed=248,\n",
    "                                                     num_class = 4), \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='accuracy',\n",
    "                        n_jobs = -1,\n",
    "                        cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch1, param_test1, 'max_depth', 'min_child_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = xgb.XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    num_class = 4,\n",
    "    objective= 'multi:softmax',\n",
    "    n_jobs = -1,\n",
    "    seed=248,\n",
    "    max_depth = 2,\n",
    "    min_child_weight = 4)\n",
    "\n",
    "cvresult = xgb.cv(xgb2.get_xgb_params(), dtrain, num_boost_round=xgb2.n_estimators, nfold=5,\n",
    "                      metrics='merror', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for optimal min_split_loss\n",
    "param_test2 = {'min_split_loss':[i/100.0 for i in range(0,2, 1)]}\n",
    "gsearch2 = GridSearchCV(estimator = xgb.XGBClassifier(n_estimators=6, \n",
    "                                                     objective= 'multi:softmax',\n",
    "                                                     seed=248,\n",
    "                                                     num_class = 4,\n",
    "                                                     max_depth = 2,\n",
    "                                                     min_child_weight = 4), \n",
    "                        param_grid = param_test2, \n",
    "                        scoring='accuracy',\n",
    "                        n_jobs = -1,\n",
    "                        cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = xgb.XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    num_class = 4,\n",
    "    objective= 'multi:softmax',\n",
    "    n_jobs = -1,\n",
    "    seed=248,\n",
    "    max_depth = 2,\n",
    "    min_child_weight = 4,\n",
    "    gamma = 0)\n",
    "\n",
    "cvresult = xgb.cv(xgb3.get_xgb_params(), dtrain, num_boost_round=xgb3.n_estimators, nfold=5,\n",
    "                      metrics='merror', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    "    'subsample':[i/100.0 for i in range(5,105, 5)],\n",
    "    'colsample_bytree':[i/100.0 for i in range(0,105, 5)]}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBClassifier(n_estimators=6, \n",
    "                                                      max_depth=2,\n",
    "                                                      min_child_weight=4, \n",
    "                                                      gamma=0, \n",
    "                                                      objective= 'multi:softmax',\n",
    "                                                      seed=248,\n",
    "                                                      num_class = 4), \n",
    "                        param_grid = param_test3, \n",
    "                        scoring='accuracy',\n",
    "                        cv=5,\n",
    "                       n_jobs = -1)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch3, param_test3, 'subsample', 'colsample_bytree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = xgb.XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    num_class = 4,\n",
    "    objective= 'multi:softmax',\n",
    "    tree_method = 'auto',\n",
    "    n_jobs = -1,\n",
    "    seed=248,\n",
    "    max_depth = 3,\n",
    "    min_child_weight = 4,\n",
    "    gamma = 0,\n",
    "    colsample_bytree = 0.8,\n",
    "    subsample = 0.65)\n",
    "\n",
    "cvresult = xgb.cv(xgb4.get_xgb_params(), dtrain, num_boost_round=xgb4.n_estimators, nfold=5,\n",
    "                      metrics='merror', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'reg_alpha':[0, 10**-5, 10**-4, 10**-3, 10**-2, 10**-2, 10**-1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = xgb.XGBClassifier(n_estimators=36, \n",
    "                                                      max_depth=3,\n",
    "                                                      min_child_weight=4, \n",
    "                                                      gamma=0, \n",
    "                                                      colsample_bytree = 0.8,\n",
    "                                                      subsample = 0.65,\n",
    "                                                      objective= 'multi:softmax',\n",
    "                                                      tree_method = 'hist',\n",
    "                                                      seed=248,\n",
    "                                                      num_class = 4), \n",
    "                        param_grid = param_test4, \n",
    "                        scoring='accuracy',\n",
    "                        cv=5,\n",
    "                        n_jobs = -1)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTuningResults_L1(model, parameter, name):\n",
    "    param_name = 'param_' + parameter\n",
    "    \n",
    "    test_scores = model.cv_results_['mean_test_score'][:9]\n",
    "    param_values = list(model.cv_results_[param_name])[:9]\n",
    "    \n",
    "    fig= plt.figure(figsize = (12, 8))\n",
    "    plt.plot(param_values, test_scores)\n",
    "    plt.ylim(ymin = 0, ymax = 1)\n",
    "    plt.ylabel('Test accuracy', size = 20)\n",
    "    plt.xlabel(name, size = 20)\n",
    "    plt.yticks(size = 20)\n",
    "    plt.xticks(param_values, size = 14)\n",
    "    plt.title('Accuracy vs. ' + name, size = 24)\n",
    "    plt.tight_layout(pad = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults_L1(gsearch4, 'reg_alpha', 'L1 Regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb5 = xgb.XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    num_class = 4,\n",
    "    objective= 'multi:softmax',\n",
    "    tree_method = 'auto',\n",
    "    n_jobs = -1,\n",
    "    seed=248,\n",
    "    max_depth = 3,\n",
    "    min_child_weight = 4,\n",
    "    gamma = 0,\n",
    "    colsample_bytree = 0.8,\n",
    "    subsample = 0.65,\n",
    "    reg_alpa = 0.1)\n",
    "\n",
    "cvresult = xgb.cv(xgb5.get_xgb_params(), dtrain, num_boost_round=xgb5.n_estimators, nfold=5,\n",
    "                      metrics='merror', early_stopping_rounds=50)\n",
    "cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'n_estimators' : range(50, 1050, 50),\n",
    " 'learning_rate' : [i/100.0 for i in range(1, 20, 1)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = xgb.XGBClassifier(max_depth=4,\n",
    "                                                      min_child_weight=3, \n",
    "                                                      gamma=0, \n",
    "                                                      subsample=0.8, \n",
    "                                                      colsample_bytree=0.65,\n",
    "                                                      req_alpha = 0.1,\n",
    "                                                      objective= 'multi:softmax', \n",
    "                                                      nthread=4, \n",
    "                                                      scale_pos_weight=1,\n",
    "                                                      seed=248,\n",
    "                                                      num_class = 4), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1, \n",
    "                        cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotTuningResults3D(gsearch5, param_test5, 'learning_rate', 'n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final = xgb.XGBClassifier(\n",
    "    learning_rate = 0.15,\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3,\n",
    "    gamma=0,\n",
    "    col_sample_bytree = 0.8,\n",
    "    subsample = .65,\n",
    "    req_alpha = 0.1,\n",
    "    objective= 'multi:softmax',\n",
    "    tree_method = 'auto',\n",
    "    seed=248,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final.get_xgb_params()\n",
    "xgb_final.fit(X_train, y_train)\n",
    "print(metrics.accuracy_score(y_test.values, xgb_final.predict(X_test)))\n",
    "\n",
    "feat_imp = pd.Series(xgb_final.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp[:30].plot(kind='bar', title='')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
